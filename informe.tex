\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[spanish]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{xcolor}
\floatname{algorithm}{Algoritmo}


\title{Multiple Importance Sampling}
\author{santiolmedo99}
\date{July 2023}

\begin{document}

\maketitle

\section{Introducción}

En computación gráfica, los problemas de renderizado están llenos de problemas de integración.
Comúnmente, estás integrales son "difíciles", es decir, las funciones a integrar son discontinuas, multidimensionales o singulares y no tienen soluciones analíticas.
Es por ello que se recurre a métodos de resolución numéricos que permiten aproximar el valor de la integral con baja varianza.
Por la naturaleza de los problemas de renderizado, donde por ejemplo, se requiere renderizar cada pixel de una imagen en tiempo real, es necesario que los métodos de resolución sean eficientes en tiempo de ejecución y errores de estimación.
Los métodos comunes, como la integración trapezoidal o cuadratura de Gauss son efectivos para la resolución de problemas de baja dimensión pero no son escalables a los problemas que aparecen en computación gráfica.
La integración por Monte Carlo es particularmente atractivo porque su convergencia es independiente de la dimensionalidad del problema.

Otro atractivo del método de Monte Carlo es su facilidad de implementación. A priori, dado

$$ \int f(x) \,d(x)$$

solo se necesita la capacidad de evaluar $f(x)$ en un punto dado para poder estimar el valor de la integral.

Debido a los problemas de integración que aparecen en computación gráfica, es necesario recurrir a métodos de Monte Carlo que permitan reducir la varianza de la estimación.
En este trabajo se presenta la técnica de Multiple Importance Sampling (MIS) que permite combinar múltiples distribuciones de muestreo para reducir la varianza de la estimación.

El informe está organizado de la siguiente manera: en la sección 2 se presenta el método de Monte Carlo.
En la sección 3 se presenta la técnica de Multiple Importance Sampling y un estudio del estado del arte.
En la sección 4 se presentan los resultados de la implementación de MIS en un subconjunto de las heurísticas analizadas.
Esta comparación se basa en el tiempo de cálculo requerido para obtener una estimación precisa, el número de muestras requeridas y la variabilidad de las estimaciones (estimación de la varianza).


\section{Monte Carlo}

En general, los métodos numéricos que se fundamentan en la evaluación de \( n \) puntos dentro de un espacio de dimensión \( m \) para obtener una solución aproximada presentan un error que disminuye en el mejor de los casos en proporción a \( n^{-1/m} \).
Esta característica los hace extremadamente ineficientes en situaciones donde \( m \) es grande.

Por otro lado, los métodos de Monte Carlo generan estimaciones cuyo error absoluto es del orden de \( n^{-1/2} \), independientemente de la dimensión \( m \). Esta cualidad representa la ventaja principal del método y, en muchos casos, hace que sea la única opción viable.

Supongamos que deseo calcular un cierto valor $\phi$, y conozco una variable aleatoria $X$ con distribución $F_X$ tal que $\phi = \mathbb{E}(X)$. El método de Monte Carlo en su versión más simple consiste en:

\begin{algorithm}
\caption{Esquema básico de un Método Monte Carlo}
\begin{algorithmic}[1]

\State \textbf{sortear} valores para un conjunto $X^{(1)}, X^{(2)}, \dots, X^{(n)}$, de variables aleatorias i.i.d. (independientes e idénticamente distribuidas) a $X$.

\State Calcular $S_n = X^{(1)} + \dots + X^{(n)}$, la suma de los $n$ valores sorteados.

\State Calcular $\hat{X} = \frac{S_n}{n}$.

\State Calcular $\hat{V} = \left(\sum_{i=1}^{n} (X^{(i)})^2\right) / (n(n - 1)) - \hat{X}^2 / (n - 1)$.

\end{algorithmic}
\end{algorithm}

Se dice que $\hat{X}$ es un estimador de $\phi$ y $\hat{V}$ es un estimador de la varianza de $\hat{X}$.

Ahora, supongamos que se quiere evaluar el valor de la integral $I = \int_{a}^{b} f(x) \,dx$. Dado un conjunto de $n$ variables aleatorias $X_1, X_2, \dots, X_n$ independientes e idénticamente distribuidas con distribución $p(x)$, se puede decir que el valor esperado del estimador
$$F = \frac{b-a}{n} \sum_{i=1}^{n} f(X_i)$$
es igual a $I$. Esto se puede ver de la siguiente manera:
$$E[F] = E\left[\frac{b-a}{n} \sum_{i=1}^{n} f(X_i)\right] = \frac{b-a}{n} \sum_{i=1}^{n} E[f(X_i)] = \frac{b-a}{n} \sum_{i=1}^{n} \int_{a}^{b} f(x) p(x) \,dx = \int_{a}^{b} f(x) \,dx.$$
Dado que $X_i$ es muestreado de $[a,b]$, $p(x) = \frac{1}{b-a}$ para $x \in [a,b]$. Entonces, sustituyendo $p(x)$ por $\frac{1}{b-a}$, y haciendo $\frac{b-a}{n} * n = b-a$, se cancela con $\frac{1}{b-a}$, y se obtiene la última igualdad.

Esto se puede extender a
$$ F = \frac{1}{n} \sum_{i=1}^{n} \frac{f(X_i)}{p(X_i)}$$
es igual a I con la condición de que $p(x) > 0$. De manera parecida, se puede ver que el valor esperado del estimador:
$$E[F] = E\left[\frac{1}{n} \sum_{i=1}^{n} \frac{f(X_i)}{p(X_i)}\right] = \frac{1}{n} \sum_{i=1}^{n} \int_{a}^{b} \frac{f(x)}{p(x)} p(x) \,dx = \frac{1}{n} \sum_{i=1}^{n} \int_{a}^{b} f(x) \,dx = \int_{a}^{b} f(x) \,dx$$

Ahora, es importante mostrar el error de la estimación. Para esto, se puede usar el estimador del esquema básico de Monte Carlo para la varianza de $F$:

$$V[\frac{1}{n}\sum_{i=1}^{n} X_{(i)}] = \frac{1}{n^{2}} \sum_{i=1}^{n} V[X_{(i)}]$$

dado que las variables aleatorias $X_{i}$ son independientes. Teniendo en cuenta que $X_{i}$ tienen la misma distribución y por lo tanto la misma varianza, se puede escribir:

$$V[F] = \frac{1}{n^{2}} \sum_{i=1}^{n} V[X_{(i)}] = \frac{1}{n^{2}} * n * \sigma^{2} = \frac{\sigma^{2}}{n}$$.

Por lo tanto, el error de la estimación es $\frac{\sigma^{2}}{n}$, que es del orden de $n^{-1/2}$.

El estimador que se obtinene es insesgado, es decir, $E[F] = I$. Cuando el estimador es sesgado, la diferencia:

$$\beta = E[F] - I$$

es el sesgo.

\section{Multiple Importance Sampling}

En esta sección se va a presentar la técnica de Multiple Importance Sampling (MIS) y un estudio del estado del arte.

\subsection{Motivación}

Tenemos una integral que puede ser de de la forma
$$ \int f_{1}(x) * f_{2}(x) * f_{3}(x) * ... * f_{k}(x) \,d(x)$$

y $ p_{1}, p_{2}, p_{3}, ..., p_{k}$ proporcionales a $f_{1}, f_{2}, f_{3}, ..., f_{k}$.
La idea es usar las distintas distribuciones de muestreo y combinarlas para encontrar una estimación de la integral con menor varianza y en poco tiempo de cómputo.

El problema también es que la inherencia de la computación gráfica hace que las funciones a integrar dependan de varios parámetros del modelo de la escena.
Esto hace que sea difícil encontrar una distribución de muestreo que sea buena para todos los parámetros.
Por lo tanto, se puede usar MIS para combinar varias distribuciones de muestreo y obtener una estimación con menor varianza para todo el espacio de parámetros.

En las próximas subsecciones se van a presentar las técninas para combinas las distribuciones de muestreo.
No se explica cómo conseguir las distribuciones de muestreo, sino que se asume que se tienen las distribuciones de muestreo y se trabaja sobre conseguir combinaciones que permitan construir un estimador con menor varianza.

\subsection{Veach}

Veach propone en su tesis técnicas para combinas las distribuciones y obtener un estimador con varianza baja y demostrablemente bueno.
En su tesis presenta el modelo multi-sample y distintas heurísticas para combinar las distribuciones de muestreo.
A su vez, presenta el modelo one-sample que consiste en elegir en cada corrida una distribución de muestreo y usarla para estimar la integral.

\subsubsection{Modelo multi-sample}

Queremos estimar:

$$ \int f_(x) \,d\mu(x)$$

donde el dominio de integración es $\Omega$ y $\mu$ es dado. Tenemos $n$ distribuciones de muestreo $p_{1}, p_{2}, ..., p_{n}$, en el dominio $\Omega$.
Tenemos las siguientes operaciones:
\begin{itemize}
    \item dado $x \in \Omega$, podemos evaluar $f(x)$ y $p_{i}(x)$
    \item la posibilidad de generar una muestra X con distribución $p_{i}$
\end{itemize}

Notación:
\begin{itemize}
    \item $n_{i}$: número de muestras generadas con $p_{i}$. Este numéro es conocido a priori.
    \item $N = \sum_{i=1}^{n} n_{i}$: número total de muestras
    \item Para $j \in \{1, 2, ..., N\}$, $X_{i,j}$ es la $j$-ésima muestra generada con $p_{i}$
\end{itemize}

\subsubsection{Estimador multi-sample}

Objetivo: encontrar un estimador insesgado combinando las muestras generadas con las distintas distribuciones de muestreo.
Para esto, consideramos estimadores que le dan pesos diferentes a cada muestra.
El estimador multi-sample es de la forma:

$$F = \sum_{i=1}^{n} \frac{1}{n_{i}} \sum_{j=1}^{n_{i}} w_{i}(X_{i,j}) \frac{f(X_{i,j})}{p_{i}(X_{i,j})}$$

donde se tiene que cumplir que:

\begin{itemize}
    \item $\sum_{i=1}^{n} w_{i}(x) = 1$ si $f(x) \neq 0$
    \item $w_{i}(x) = 0$ si $p_{i}(x) = 0$
\end{itemize}

Esto implica que en cada punto donde f(x) es distinto de 0, al menos una de $p_{i}(x)$ es positivo.

Lema de que el estimador es insesgado:

$$E[F] = \int f_(x) \,d\mu(x)$$

Podemos demostrar que:
\begin{align*}
E[F] &= E\left[\sum_{i=1}^n \frac{1}{n_i} \sum_{j=1}^{n_i} w_i(X_{i,j}) \frac{f(X_{i,j})}{p_i(X_{i,j})}\right] \\
&= \sum_{i=1}^n \frac{1}{n_i} E\left[\sum_{j=1}^{n_i} w_i(X_{i,j}) \frac{f(X_{i,j})}{p_i(X_{i,j})}\right] \\
&= \sum_{i=1}^n \frac{1}{n_i} \sum_{j=1}^{n_i} \int_{\Omega} w_i(x) \frac{f(x)}{p_i(x)} p_i(x) d\mu(x) \\
&= \int_{\Omega} \left(\sum_{i=1}^n w_i(x)\right) f(x) d\mu(x) \\
&= \int_{\Omega} f(x) d\mu(x),
\end{align*}
dado que por la condición \( (W1) \), \( \sum_{i=1}^n w_i(x) = 1 \) siempre que \( f(x) \neq 0 \).

Por lo tanto, el estimador \( F \) es imparcial. La última igualdad se debe a que \( \sum_{i=1}^n w_i(x) = 1 \) cuando \( f(x) \neq 0 \).

\subsubsection{Balance Heuristic}

$$ w_{i}(x) = \frac{n_{i} * p_{i}(x)}{\sum_{k} n_{k} * p_{k}(x)}$$

\textbf{Teorema 9.2} Dado $f$, $n_{i}$ y $p_{i}$ para $i \in \{1, 2, ..., n\}$. Sea F cualquier estimador insesgado de la forma del multi-sample estimator y \hat{F} el estimador balance heuristic. Entonces:

$$V[\hat{F}] - V[F] \leq ( \frac{1}{min_{i} n_{i}} - \frac{1}{\sum_{i} n_{i}} ) * \mu^{2}$$

donde $\mu = E[F] = E[\hat{F}]$.

% \textbf{Demostración}:

% Sean:

% $$ F_{i}{j} = \frac{w_{i}(X_{i,j}) f(X_{i,j})}{p_{i}(X_{i,j})}$$

% y

% $$ \mu_{i} = E[F_{i}{j}] =  \int_{\Omega} w_{i}(x) f(x) d\mu(x)$$.

% Entonces:

% \begin{align*}
%   V[F] &= V\left[\sum_{i=1}^n \frac{1}{n_i} \sum_{j=1}^{n_i} F_{i,j}\right] \\
%   &= \sum_{i=1}^n \frac{1}{n_i^2} \sum_{j=1}^{n_i} V[F_{i,j}] \\
%   &= \left(\sum_{i=1}^n \frac{1}{n_i^2} \sum_{j=1}^{n_i} E[F_{i,j}^2]\right) - \left(\sum_{i=1}^n \frac{1}{n_i^2} \sum_{j=1}^{n_i} E[F_{i,j}]^2\right) \\
%   &= \left(\sum_{i=1}^n \frac{1}{n_i^2} \sum_{j=1}^{n_i} \int_{\Omega} \frac{w_i(x)^2 f(x)^2}{p_i(x)^2} p_{i}(x) d\mu(x)\right) - \left(\sum_{i=1}^n \frac{1}{n_i^2} n_i  \mu_i^2\right) \\
%   &= \int_{\Omega} \left(\sum_{i=1}^n \frac{w_i(x)^2 f(x)^2}{n_i p_i(x)} d\mu(x)\right) - \left(\sum_{i=1}^n \frac{\mu_i^2}{n_i}\right).
% \end{align*}

% ... seguir viendo y entendiendo la demostración.

\subsubsection{Otras Heurísticas}

Dentro de los límites presentados en el Teorema 9.2, Veach presenta más heurísticas que son demostrablemente mejores que balance heuristic en circinstancias particulares.
Estas heurísticas son insesgadas al igual que balance heuristic.

Se considera la situación donde una de las distribuciones de muestreo es un match perfecto para la función a integrar. En este caso, es deseable que la heurística le de un peso de 1 a esta distribución de muestreo y 0 a las demás. (hacer referencia a la imagen)
La idea entonces es ir sampleando con las distintas distribuciones de muestreo y darle un peso de 1 en todo el dominio a la distribución de muestreo cercana a $f$ y 0 a las demás.
Sería como tomar muestras solo de la distribución de muestreo cercana a $f$ pero de igual manera tomando muestras de todas porque no se sabe de antemano cuál es la distribución de muestreo cercana a $f$.

Para encontrar la heurística se toma como ejemplo la función donde $p1$ es un match perfecto para $f$ y $p2$ es una constante.
Se quiere encontrar una heurística que le de un peso de 1 a $p1$ y 0 a $p2$.

\section{Experimentación práctica}

Dentro de esta sección se presenta la implementación de MIS en un conjunto de pruebas que permite analizar el comportamiento de MIS en distintos escenarios.

\subsection{Prueba 1 - Análisis de un caso simple}
\color{red}
EN TODO ESTA PRUEBA SACAR TODO A LO QUE HAGA REFERENCIA EL MEAN OF ERRORS, ESTA MAL
\color{black}

La primera función se utlizó para familiarizarse con el algoritmo y verificar que el código implementado funcionaba correctamente.
Se corroboró la correctitud del MIS implementado usando distintas heurísticas y se utilizó el código como base para las pruebas siguientes.

\subsubsection{Función}
La función que examinamos se define para un conjunto de valores \( x \) y rangos específicos. Para cada rango \( [a, b] \), la función se expresa como:
\begin{equation}
f(x) = \sum \max\left(0, -\frac{4}{(b - a)^2} (x - a)(x - b)\right)
\end{equation}
Aquí, la suma se lleva a cabo sobre los diferentes rangos considerados.

\subsubsection{Distribuciones de Muestreo}
La PDF utilizada corresponde a la de una distribución normal, caracterizada por una media \( \mu \) y una desviación estándar \( \sigma \). La fórmula es la siguiente:
\begin{equation}
p(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)
\end{equation}

La función que examinamos se define para un conjunto de valores \( x \) y rangos específicos. Para cada rango \( [a, b] \), la función se expresa como:
\begin{equation}
f(x) = \sum \max\left(0, -\frac{4}{(b - a)^2} (x - a)(x - b)\right)
\end{equation}
Aquí, la suma se lleva a cabo sobre los diferentes rangos considerados.

\subsubsection{Función de Densidad de Probabilidad (PDF)}
La PDF utilizada corresponde a la de una distribución normal, caracterizada por una media \( \mu \) y una desviación estándar \( \sigma \). La fórmula es la siguiente:
\begin{equation}
p(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)
\end{equation}

\subsubsection{Ejemplo}

Para poder visualizar la función se considera el siguiente ejemplo donde:

\begin{itemize}
    \item \textbf{\( \mu_{i} \)}: [5, 10, 15]
    \item \textbf{\( \sigma_{i} \)}: [1.0, 0.5, 0.75]
    \item \textbf{\( a_{i} \)}: [3.0, 9.0, 13.5]
    \item \textbf{\( b_{i} \)}: [7.0, 11.0, 16.5]
\end{itemize}

En la figura se puede ver la función \( f(x) \) y las distribuciones de muestreo \( p_{i}(x) \) para cada rango \( [a_{i}, b_{i}] \).
A su vez, se hizo una corrida con balance heuristic y ver en rojo los puntos muestreados.
%poner imagen

\subsubsection{Pruebas realizadas}

Sobre este caso de prueba se generó un análisis de las distintas heurísticas implementadas.
Para el análisis se hizo lo siguiente:
\begin{itemize}
    \item Se hicieron 10 tests diferentes. Para cada test se generaron valores aleatiorios para \( \mu_{i} \), \( \sigma_{i} \), \( a_{i} \) y \( b_{i} \).
          Por simplicidad, para el primer rango de  \( \mu_{i} \) se fijaron los valores entre 2 y 7.
          Para el segundo rango de \( \mu_{i} \) se fijaron los valores entre 7 y 12.
          Para el tercer rango de \( \mu_{i} \) se fijaron los valores entre 12 y 18.
          Las desviaciones estándar \( \sigma_{i} \) se fijaron entre 0.01 y 1.
          Los rangos \( [a_{i}, b_{i}] \) se calcularon como \( [ \mu_{i} - 2 * \sigma_{i}, \mu_{i} + 2 * \sigma_{i} ] \).
    \item Para cada test se corrió MIS con las siguientes heurísticas: balance, power, maximum, cutoff y sbert.
    \item Para cada heurística se corrió MIS con 10, 25, 50, 100 y 150 muestras.
    \item Para cada heurística y cantidad de muestras se corrió MIS 100 veces y se calculó el promedio de las estimaciones,
          el promedio de la varianza de las estimaciones y el promedio de las desviaciones estándar de las estimaciones.
          A su vez, se calculó el promedio de los errores comparados con una estimación hecha con quad y el promedio del tiempo de cómputo.
\end{itemize}

Una, vez hecho esto, debido a la extensión de los resultados, se decidió hacer el siguiente análisis de la varianza de las estimaciones, las desviaciones estándar de las estimaciones, el error de las estimaciones y el promedio del error de las desviaciones en comparación con quad.
Este análisis se hizo para:

\begin{itemize}
    \item Cada heurística y cantidad de muestras combinadas.
    \item Cada heurística dentro de cada test.
    \item Cada heurística.
\end{itemize}

\subsubsection{Resultados}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Heuristic/Sample Size} & \textbf{10} & \textbf{25} & \textbf{50} & \textbf{100} & \textbf{150} \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Variances}} \\ \hline
Balance & 0.4441 & 0.1579 & 0.0735 & 0.0376 & 0.0247 \\ \hline
Power & 0.4505 & 0.1615 & 0.0749 & 0.0384 & 0.0253 \\ \hline
Maximum & 0.4766 & 0.1719 & 0.0797 & 0.0408 & 0.0269 \\ \hline
Cutoff & 0.4575 & 0.1642 & 0.0760 & 0.0389 & 0.0257 \\ \hline
SBERT & 0.4423 & 0.1584 & 0.0734 & 0.0374 & 0.0247 \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Errors}} \\ \hline
Balance & 0.3021 & 0.1882 & 0.1292 & 0.0940 & 0.0764 \\ \hline
Power & 0.3141 & 0.1968 & 0.1338 & 0.0961 & 0.0775 \\ \hline
Maximum & 0.3258 & 0.2025 & 0.1411 & 0.0992 & 0.0815 \\ \hline
Cutoff & 0.3198 & 0.1990 & 0.1337 & 0.0976 & 0.0790 \\ \hline
SBERT & 0.3065 & 0.1886 & 0.1303 & 0.0941 & 0.0749 \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Standard Deviations}} \\ \hline
Balance & 0.6009 & 0.3674 & 0.2533 & 0.1818 & 0.1477 \\ \hline
Power & 0.6059 & 0.3727 & 0.2563 & 0.1843 & 0.1496 \\ \hline
Maximum & 0.6238 & 0.3848 & 0.2646 & 0.1900 & 0.1545 \\ \hline
Cutoff & 0.6112 & 0.3762 & 0.2583 & 0.1856 & 0.1510 \\ \hline
SBERT & 0.6003 & 0.3685 & 0.2533 & 0.1815 & 0.1475 \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Mis-Estimate Differences}} \\ \hline
Balance & 0.0122 & 0.0062 & 0.0036 & 0.0028 & 0.0019 \\ \hline
Power & 0.0078 & 0.0062 & 0.0051 & 0.0039 & 0.0024 \\ \hline
Maximum & 0.0135 & 0.0066 & 0.0041 & 0.0015 & 0.0015 \\ \hline
Cutoff & 0.0089 & 0.0068 & 0.0058 & 0.0045 & 0.0032 \\ \hline
SBERT & 0.0148 & 0.0059 & 0.0031 & 0.0042 & 0.0033 \\ \hline
\end{tabular}
\caption{Analysis of the results per heuristic and sample size}
\label{table:heuristic_analysis}
\end{table}

\begin{table}[H]
\centering
\caption{Analysis of the results per heuristic in each test}
\label{table:heuristic_test_analysis}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Heuristic/Test} & \textbf{Mean of Variances} & \textbf{Mean of Errors} & \textbf{Mean of Std. Deviations} & \textbf{Mean of Misestimate Differences} \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 1}} \\ \hline
Balance & 0.1039 & 0.2199 & 0.2665 & 0.0067 \\ \hline
Power & 0.1015 & 0.2181 & 0.2645 & 0.0103 \\ \hline
Maximum & 0.1023 & 0.2155 & 0.2657 & 0.0024 \\ \hline
Cutoff & 0.1026 & 0.2172 & 0.2646 & 0.0091 \\ \hline
SBERT & 0.1035 & 0.2151 & 0.2662 & 0.0050 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 2}} \\ \hline
Balance & 0.1625 & 0.1883 & 0.3500 & 0.0055 \\ \hline
Power & 0.1640 & 0.1944 & 0.3512 & 0.0081 \\ \hline
Maximum & 0.1641 & 0.1872 & 0.3518 & 0.0065 \\ \hline
Cutoff & 0.1628 & 0.1925 & 0.3507 & 0.0075 \\ \hline
SBERT & 0.1630 & 0.1869 & 0.3501 & 0.0060 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 3}} \\ \hline
Balance & 0.0907 & 0.1986 & 0.2497 & 0.0047 \\ \hline
Power & 0.0912 & 0.1999 & 0.2503 & 0.0040 \\ \hline
Maximum & 0.0890 & 0.2001 & 0.2480 & 0.0082 \\ \hline
Cutoff & 0.0936 & 0.2012 & 0.2531 & 0.0076 \\ \hline
SBERT & 0.0950 & 0.2058 & 0.2543 & 0.0139 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 4}} \\ \hline
Balance & 0.3690 & 0.1569 & 0.5303 & 0.0088 \\ \hline
Power & 0.3670 & 0.1618 & 0.5295 & 0.0045 \\ \hline
Maximum & 0.3659 & 0.1592 & 0.5288 & 0.0054 \\ \hline
Cutoff & 0.3675 & 0.1598 & 0.5296 & 0.0038 \\ \hline
SBERT & 0.3644 & 0.1593 & 0.5278 & 0.0032 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 5}} \\ \hline
Balance & 0.0929 & 0.1888 & 0.2582 & 0.0062 \\ \hline
Power & 0.1225 & 0.2294 & 0.2969 & 0.0084 \\ \hline
Maximum & 0.2178 & 0.3147 & 0.3975 & 0.0118 \\ \hline
Cutoff & 0.1440 & 0.2555 & 0.3215 & 0.0082 \\ \hline
SBERT & 0.0920 & 0.1914 & 0.2575 & 0.0083 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 6}} \\ \hline
Balance & 0.2760 & 0.1540 & 0.4588 & 0.0057 \\ \hline
Power & 0.2763 & 0.1556 & 0.4590 & 0.0032 \\ \hline
Maximum & 0.2750 & 0.1546 & 0.4584 & 0.0045 \\ \hline
Cutoff & 0.2748 & 0.1568 & 0.4581 & 0.0062 \\ \hline
SBERT & 0.2740 & 0.1519 & 0.4578 & 0.0086 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 7}} \\ \hline
Balance & 0.0882 & 0.1069 & 0.2594 & 0.0029 \\ \hline
Power & 0.0878 & 0.1086 & 0.2590 & 0.0029 \\ \hline
Maximum & 0.0874 & 0.1079 & 0.2585 & 0.0023 \\ \hline
Cutoff & 0.0877 & 0.1107 & 0.2589 & 0.0037 \\ \hline
SBERT & 0.0879 & 0.1097 & 0.2590 & 0.0029 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 8}} \\ \hline
Balance & 0.0354 & 0.0917 & 0.1630 & 0.0023 \\ \hline
Power & 0.0352 & 0.0921 & 0.1628 & 0.0015 \\ \hline
Maximum & 0.0353 & 0.0884 & 0.1628 & 0.0030 \\ \hline
Cutoff & 0.0347 & 0.0907 & 0.1620 & 0.0047 \\ \hline
SBERT & 0.0357 & 0.0912 & 0.1636 & 0.0020 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 9}} \\ \hline
Balance & 0.2219 & 0.1498 & 0.4122 & 0.0026 \\ \hline
Power & 0.2221 & 0.1523 & 0.4124 & 0.0049 \\ \hline
Maximum & 0.2220 & 0.1523 & 0.4124 & 0.0052 \\ \hline
Cutoff & 0.2224 & 0.1498 & 0.4126 & 0.0025 \\ \hline
SBERT & 0.2230 & 0.1528 & 0.4128 & 0.0098 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 10}} \\ \hline
Balance & 0.0351 & 0.1247 & 0.1543 & 0.0081 \\ \hline
Power & 0.0337 & 0.1245 & 0.1521 & 0.0031 \\ \hline
Maximum & 0.0332 & 0.1202 & 0.1515 & 0.0054 \\ \hline
Cutoff & 0.0348 & 0.1242 & 0.1538 & 0.0049 \\ \hline
SBERT & 0.0340 & 0.1248 & 0.1529 & 0.0029 \\ \hline
\end{tabular}%
}
\end{table}

\begin{table}[H]
\centering
\caption{Analysis of the results per heuristic}
\label{table:heuristic_analysis}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Heuristic} & \textbf{Mean of Variances} & \textbf{Mean of Errors} & \textbf{Mean of Std. Deviations} & \textbf{Mean of Misestimate Differences} \\ \hline
Balance & 0.1476 & 0.1580 & 0.3102 & 0.0054 \\ \hline
Power & 0.1501 & 0.1637 & 0.3138 & 0.0051 \\ \hline
Maximum & 0.1592 & 0.1700 & 0.3235 & 0.0055 \\ \hline
Cutoff & 0.1525 & 0.1658 & 0.3165 & 0.0058 \\ \hline
SBERT & 0.1473 & 0.1589 & 0.3102 & 0.0063 \\ \hline
\end{tabular}%
}
\end{table}


\paragraph{Diferencias entre Heurísticas}
Varianza de las Estimaciones: Las heurísticas 'Balance' y 'SBERT' muestran consistentemente las varianzas más bajas a través de todos los tamaños de muestra, lo que indica una mayor precisión en sus estimaciones.
Por otro lado, 'Maximum' presenta la varianza más alta, especialmente con tamaños de muestra más pequeños, lo que sugiere una menor fiabilidad en comparación con otras heurísticas.

Error de las Estimaciones: En términos de errores, 'Balance' y 'SBERT' nuevamente muestran un desempeño superior, especialmente a medida que aumenta el tamaño de la muestra. 'Maximum' y 'Cutoff' tienen errores ligeramente más altos, lo que indica una menor precisión en sus estimaciones.

Desviaciones Estándar de las Estimaciones: Las heurísticas 'Balance', 'Power', y 'SBERT' mantienen desviaciones estándar más bajas, lo que sugiere estimaciones más consistentes.
'Maximum' presenta la mayor desviación estándar, reafirmando su menor consistencia en las estimaciones.

Diferencias en las Estimaciones de MIS: 'Balance' y 'SBERT' muestran las menores diferencias en las estimaciones de MIS, lo que indica una mayor precisión en sus resultados.
Las heurísticas 'Maximum' y 'Cutoff' presentan diferencias más significativas, lo que podría indicar una mayor variabilidad en sus estimaciones.

\paragraph{Competitividad del MIS en Función del Tamaño de Muestra}
Se observa que a medida que el tamaño de la muestra aumenta, todas las heurísticas mejoran en términos de varianza, error, y desviación estándar de las estimaciones. Esto es un indicativo de que el MIS se vuelve más competitivo y confiable con un mayor número de muestras.
Específicamente, con tamaños de muestra de 50 en adelante, se empieza a notar una mejora significativa en la precisión y consistencia de las estimaciones para todas las heurísticas.
Las heurísticas 'Balance' y 'SBERT' demuestran ser competitivas incluso con tamaños de muestra más pequeños (25 muestras), mientras que otras heurísticas como 'Maximum' y 'Cutoff' requieren tamaños de muestra mayores para alcanzar niveles similares de precisión y confiabilidad.

En resumen, las heurísticas 'Balance' y 'SBERT' muestran un rendimiento superior en términos de varianza, error y consistencia de las estimaciones a través de todos los tamaños de muestra. El MIS se vuelve notablemente más competitivo y preciso con tamaños de muestra de 50 o más, aunque algunas heurísticas como 'Balance' y 'SBERT' ya muestran resultados prometedores con tamaños de muestra de 25. En contraste, heurísticas como 'Maximum' y 'Cutoff' requieren tamaños de muestra más grandes para ofrecer un nivel de precisión y consistencia comparable.

\subsection{Prueba 2 - Análisis Multidimensional}

En esta sección, nos centramos en el análisis de una función multidimensional basada en la función hiperbólica \textit{sech}, extendida a múltiples dimensiones. La función \textit{sech}, definida como \( \text{sech}(x) = \frac{2}{e^x + e^{-x}} = \frac{1}{\cosh(x)} \), es conocida por su similitud con la distribución gaussiana en una dimensión, especialmente cerca del origen.

La función objetivo, \( h(\mathbf{x}) \), donde \( \mathbf{x} \) es un vector \( n \)-dimensional, es expresada como una suma de \( m \) funciones \( f_i(\mathbf{x}) \):
\[ h(\mathbf{x}) = \sum_{i=1}^{m} f_i(\mathbf{x}) \]
donde cada \( f_i(\mathbf{x}) \) es definida por:
\[ f_i(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n) = \prod_{j=1}^{n} \text{sech}(a_{ij} (x_j - b_{ij})) \]

Aquí, \( a_{ij} \) y \( b_{ij} \) son constantes positivas que determinan la anchura y la posición de la función \( f_i \) en la dimensión \( j \), respectivamente.

Para calcular el volumen (integral) de esta función sobre el espacio \( n \)-dimensional, consideramos la integral de cada componente \textit{sech}, que se simplifica a \( \frac{\pi}{a_i} \) para cada dimensión. Por lo tanto, el volumen total se obtiene como:
\[ V = \prod_{i=1}^{n} \frac{\pi}{a_i} = \frac{\pi^n}{\prod_{i=1}^{n} a_i} \]

Para la aproximación gaussiana de la función \textit{sech} en múltiples dimensiones, consideramos gaussianas estándar con medias centradas y desviaciones estándar ajustadas.
La correspondencia entre las "anchuras" de las funciones \textit{sech} y las desviaciones estándar de las gaussianas se establece mediante un mapeo aproximado, asegurando que ambas funciones tengan anchuras comparables en el punto donde caen a la mitad de su valor máximo.

El objetivo principal de este análisis es aplicar el MIS para estimar la integral de una función compleja, que es una suma de funciones \textit{sech} multidimensionales, a través de varias distribuciones propuestas.
Esta función nos va a permitir analizar el MIS en varias dimensiones y comparar las diferentes heurísticas implementadas.

En las siguientes subsecciones, detallaremos la implementación y los resultados de aplicar MIS a esta función multidimensional, examinando la eficacia de diferentes estrategias de muestreo y distribuciones propuestas.

\subsubsection{Ejemplo}

Para poder visualizar la función se considera el siguiente ejemplo donde:

\begin{itemize}
    \item \textbf{\( a_{ij} \)}: [[2, 2], [2, 2], [2, 2]]
    \item \textbf{\( b_{ij} \)}: [[91, 22], [-81, -90], [31, 29]]
\end{itemize}

En la figura se puede ver la función \( f(x) \) y las distribuciones de muestreo \( p_{i}(x) \) para cada rango \( [a_{i}, b_{i}] \).
A su vez, se hizo una corrida con balance heuristic y ver en rojo, verde y azul los puntos muestreados.
%poner imagen

\subsubsection{Pruebas realizadas}

Sobre este caso de prueba se generó un análisis de las distintas heurísticas implementadas.
Para el análisis se hizo lo siguiente:
\begin{itemize}
    \item Se hicieron 10 tests diferentes. Para cada test se generaron valores aleatiorios para \( a_{ij} \), \( b_{ij} \), \( m \) y \( n \).
          En cada test se generó un número aleatiorio entre 2 y 10 para \( m \) y \( n \) se fijó en el número del test.
          Es decir, para el primer test \( n = 1 \), para el segundo test \( n = 2 \), etc. La dimensión entonces es el número del test más 1.
          Para cada test se generaron valores aleatiorios para \( a_{ij} \) entre 1.8 y 2.
          Para cada test se generaron valores aleatiorios para \( b_{ij} \) entre -100 y 100.
    \item Para cada test se corrió MIS con las siguientes heurísticas: balance, power, maximum, cutoff y sbert.
    \item Para cada heurística se corrió MIS con 50, 100, 500, 1000 y 5000 muestras.
    \item Para cada heurística y cantidad de muestras se corrió MIS 100 veces y se calculó el promedio de las estimaciones,
          el promedio de la varianza de las estimaciones y el promedio de las desviaciones estándar de las estimaciones.
          A su vez, se calculó el promedio de los errores comparados el valor exacto de la integral y el promedio del tiempo de cómputo.
\end{itemize}

De la misma manera que para la prueba pasada, se hizo un resumen de los resultados debido a la extensión de los mismos.
Se hizo el siguiente análisis de la varianza de las estimaciones, las desviaciones estándar de las estimaciones, el error de las estimaciones.

El análisis se hizo para los mismos casos que en la prueba anterior.

\subsubsection{Resultados}

\begin{table}[H]
\centering
\caption{Analysis of the results per heuristic and sample size}
\label{table:heuristic_analysis}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Heuristic/Sample Size} & \textbf{50} & \textbf{100} & \textbf{500} & \textbf{1000} & \textbf{5000} \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Variances}} \\ \hline
Balance & 28542.80 & 11755.25 & 32890.92 & 2082.61 & 1470.44 \\ \hline
Power & 16022.84 & 136709.92 & 3707.40 & 75721.90 & 2557.03 \\ \hline
Maximum & 16750.33 & 16552.90 & 111964.69 & 3072.33 & 7038.19 \\ \hline
Cutoff & 23826.31 & 236449.12 & 74333.52 & 5878.86 & 1416.80 \\ \hline
SBERT & 6603.14 & 59408.55 & 17053.03 & 1951.91 & 7476.45 \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Errors}} \\ \hline
Balance & 3.63 & 8.93 & -1.65 & 6.80 & 6.29 \\ \hline
Power & 10.67 & -6.78 & 5.86 & -1.69 & 2.84 \\ \hline
Maximum & 8.21 & 5.28 & -6.80 & 5.43 & 1.24 \\ \hline
Cutoff & 8.08 & -12.71 & 0.51 & 2.23 & 4.12 \\ \hline
SBERT & 13.10 & -0.75 & 0.52 & 7.51 & 0.67 \\ \hline
\multicolumn{6}{|c|}{\textbf{Mean of Standard Deviations}} \\ \hline
Balance & 40.21 & 31.19 & 29.39 & 17.13 & 10.70 \\ \hline
Power & 36.94 & 46.45 & 21.71 & 26.32 & 13.61 \\ \hline
Maximum & 36.01 & 34.19 & 34.76 & 18.94 & 15.45 \\ \hline
Cutoff & 37.73 & 46.92 & 28.03 & 21.41 & 12.85 \\ \hline
SBERT & 32.84 & 39.51 & 27.41 & 16.83 & 15.55 \\ \hline
\end{tabular}%
}
\end{table}

\begin{table}[H]
\centering
\caption{Analysis of the results per heuristic in each test}
\label{table:heuristic_test_analysis}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Heuristic/Test} & \textbf{Mean of Variances} & \textbf{Mean of Errors} & \textbf{Mean of Std. Deviations} \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 1 (2 dimensions)}} \\ \hline
Balance & 0.04 & 0.03 & 0.12 \\ \hline
Power & 0.12 & 0.00 & 0.15 \\ \hline
Maximum & 30.53 & -0.24 & 0.40 \\ \hline
Cutoff & 0.07 & 0.01 & 0.14 \\ \hline
SBERT & 0.06 & 0.02 & 0.13 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 2 (3 dimensions)}} \\ \hline
Balance & 1.86 & 0.11 & 0.52 \\ \hline
Power & 0.76 & 0.11 & 0.50 \\ \hline
Maximum & 8.76 & 0.00 & 0.62 \\ \hline
Cutoff & 1.07 & 0.12 & 0.51 \\ \hline
SBERT & 2.64 & -0.02 & 0.64 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 3 (4 dimensions)}} \\ \hline
Balance & 29.51 & 0.49 & 2.21 \\ \hline
Power & 105.99 & -0.14 & 2.86 \\ \hline
Maximum & 18.16 & 0.70 & 2.06 \\ \hline
Cutoff & 23.96 & 0.28 & 2.43 \\ \hline
SBERT & 278.20 & 0.10 & 2.65 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 4 (5 dimensions)}} \\ \hline
Balance & 18.61 & 0.27 & 1.62 \\ \hline
Power & 85.91 & -0.21 & 2.14 \\ \hline
Maximum & 40.65 & -0.12 & 1.95 \\ \hline
Cutoff & 9.87 & 0.46 & 1.47 \\ \hline
SBERT & 9.34 & 0.37 & 1.54 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 5 (6 dimensions)}} \\ \hline
Balance & 481.61 & 2.76 & 11.17 \\ \hline
Power & 943.69 & 2.36 & 11.74 \\ \hline
Maximum & 1771.43 & 0.04 & 14.19 \\ \hline
Cutoff & 863.24 & 0.92 & 13.37 \\ \hline
SBERT & 724.53 & 1.85 & 12.35 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 6 (7 dimensions)}} \\ \hline
Balance & 1306.95 & 2.46 & 15.34 \\ \hline
Power & 963.76 & 3.33 & 14.93 \\ \hline
Maximum & 9279.05 & -0.52 & 18.93 \\ \hline
Cutoff & 1088.97 & 3.46 & 15.06 \\ \hline
SBERT & 1070.86 & 1.33 & 16.57 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 7 (8 dimensions)}} \\ \hline
Balance & 25439.79 & 4.67 & 45.24 \\ \hline
Power & 4664.42 & 15.44 & 36.94 \\ \hline
Maximum & 10284.54 & 8.22 & 41.82 \\ \hline
Cutoff & 7801.54 & 12.21 & 38.41 \\ \hline
SBERT & 9223.81 & 10.39 & 38.39 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 8 (9 dimensions)}} \\ \hline
Balance & 3084.19 & 7.14 & 25.95 \\ \hline
Power & 2962.02 & 8.85 & 24.88 \\ \hline
Maximum & 209686.80 & -16.35 & 49.79 \\ \hline
Cutoff & 170432.00 & -18.71 & 52.89 \\ \hline
SBERT & 2462.07 & 8.43 & 25.26 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 9 (10 dimensions)}} \\ \hline
Balance & 54957.71 & 24.84 & 83.50 \\ \hline
Power & 235542.00 & 2.03 & 107.36 \\ \hline
Maximum & 39747.77 & 17.58 & 87.42 \\ \hline
Cutoff & 33146.26 & 30.28 & 79.06 \\ \hline
SBERT & 56862.70 & 17.78 & 90.10 \\ \hline
\multicolumn{5}{|c|}{\textbf{Test 10 (11 dimensions)}} \\ \hline
Balance & 68163.77 & 5.20 & 71.55 \\ \hline
Power & 224169.45 & -9.98 & 88.55 \\ \hline
Maximum & 39889.16 & 17.40 & 61.52 \\ \hline
Cutoff & 470442.18 & -24.55 & 90.47 \\ \hline
SBERT & 114351.93 & 1.82 & 76.61 \\ \hline
\end{tabular}%
}
\end{table}

\begin{table}[H]
\centering
\caption{Analysis of the results per heuristic}
\label{table:heuristic_analysis}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Heuristic} & \textbf{Mean of Variances} & \textbf{Mean of Errors} & \textbf{Mean of Std. Deviations} \\ \hline
Balance & 15348.41 & 4.80 & 25.73 \\ \hline
Power & 46943.82 & 2.18 & 29.01 \\ \hline
Maximum & 31075.69 & 2.67 & 27.87 \\ \hline
Cutoff & 68380.92 & 0.45 & 29.39 \\ \hline
SBERT & 18498.62 & 4.21 & 26.43 \\ \hline
\end{tabular}%
}



\end{document}

\[ (\int_{\Omega} \sum_{i=1}^{n} \frac{w_{i}^{2}(x) * f^{2}(x)}{n_{i} * p_{i}(x)} \,d\mu(x)) - (\sum_{i=1}^{n} \frac{1}{n_{i}} * \mu_{i}^{2}) \]

where

\[ \mu_{i} = \int_{\Omega} w_{i}(x) * f(x) \,d\mu(x)\]

$1 \times 10^{6}$